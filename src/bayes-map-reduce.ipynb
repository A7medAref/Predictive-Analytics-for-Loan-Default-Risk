{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "from data_preprocessing import get_cleaned_data, get_cleaned_data_final\n",
    "findspark.init()\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "spark=SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"Apriori\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_cleaned_data_final(convert_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rdd = spark.createDataFrame(data.head(100_000)).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (key : class label , value : {attribute1 : value1, attribute2 : value2})\n",
    "def mapper_1(row):\n",
    "\tdict = row.asDict()\n",
    "\tdict['count'] = 1\n",
    "\tresult = {}\n",
    "\tfor k,v in dict.items():\n",
    "\t\tif k != 'TARGET':\n",
    "\t\t\tresult[k] = v\n",
    "\treturn (dict['TARGET'], result)\n",
    "\n",
    "def reducer_1(old, new):\n",
    "\tfor k,v in new.items():\n",
    "\t\told[k] = old[k] + v\n",
    "\treturn old\n",
    "\n",
    "mean = data_rdd.map(mapper_1).reduceByKey(reducer_1).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mean)\n",
    "class_counts = [mean[0][1]['count'], mean[1][1]['count']]\n",
    "for r in mean:\n",
    "\tfor k,v in r[1].items():\n",
    "\t\tr[1][k] = v / r[1]['count']\n",
    "# print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (key : class label , value : {attribute1 : value1, attribute2 : value2})\n",
    "def mapper_2(row, mean):\n",
    "\tdict = row.asDict()\n",
    "\tresult = {}\n",
    "\tfor k1, v1 in dict.items():\n",
    "\t\tfor k2, v2 in dict.items():\n",
    "\t\t\tif k1 != 'TARGET' and k2 != 'TARGET':\n",
    "\t\t\t\tresult[(k1, k2)] = (v1 - mean[dict['TARGET']][1][k1]) * (v2 - mean[dict['TARGET']][1][k2])\n",
    "\treturn (dict['TARGET'], result)\n",
    "\n",
    "def reducer_2(old, new):\n",
    "\tfor k,v in new.items():\n",
    "\t\told[k] = old[k] + v\n",
    "\treturn old\n",
    "\n",
    "cov = data_rdd.map(lambda x: mapper_2(x, mean)).reduceByKey(reducer_2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cov)\n",
    "for r in cov:\n",
    "\tfor k,v in r[1].items():\n",
    "\t\tr[1][k] = v / class_counts[r[0]]\n",
    "# print(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate numpy arrays for mean and covariance\n",
    "# TODO Make Sure Input features are in the same order\n",
    "features = [k for k,v in mean[0][1].items() if k != 'count']\n",
    "\n",
    "mean_0 = np.zeros(len(features))\n",
    "mean_1 = np.zeros(len(features))\n",
    "cov_0 = np.zeros((len(mean_0), len(mean_0)))\n",
    "cov_1 = np.zeros((len(mean_1), len(mean_1)))\n",
    "\n",
    "for f in range(len(features)):\n",
    "\tmean_0[f] = mean[0][1][features[f]]\n",
    "\tmean_1[f] = mean[1][1][features[f]]\n",
    "\n",
    "for i in range(len(features)):\n",
    "\tfor j in range(len(features)):\n",
    "\t\tcov_0[i][j] = cov[0][1][(features[i], features[j])]\n",
    "\t\tcov_1[i][j] = cov[1][1][(features[i], features[j])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34,)\n",
      "(34,)\n",
      "(34, 34)\n",
      "(34, 34)\n"
     ]
    }
   ],
   "source": [
    "print(mean_0.shape)\n",
    "print(mean_1.shape)\n",
    "print(cov_0.shape)\n",
    "print(cov_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "\t# Calculate the probability of class 0\n",
    "\tprob_0 = 1 / (2 * np.pi * np.sqrt(np.linalg.det(cov_0))) * np.exp(-0.5 * np.dot(np.dot((x - mean_0).T, np.linalg.inv(cov_0)), (x - mean_0)))\n",
    "\t# Calculate the probability of class 1\n",
    "\tprob_1 = 1 / (2 * np.pi * np.sqrt(np.linalg.det(cov_1))) * np.exp(-0.5 * np.dot(np.dot((x - mean_1).T, np.linalg.inv(cov_1)), (x - mean_1)))\n",
    "\t# Return the class with the higher probability\n",
    "\treturn 0 if prob_0 > prob_1 else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665167416291854\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_data = data.iloc[100_000:102_001]\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "\tx = np.array([test_data[f].values[i] for f in features])\n",
    "\tpred = predict(x)\n",
    "\tif pred == test_data['TARGET'].values[i]:\n",
    "\t\tcorrect += 1\n",
    "\n",
    "print(correct / len(test_data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
